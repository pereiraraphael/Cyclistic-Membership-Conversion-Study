---
title: "Google Data Analytics Capstone - Cyclistic, a bike share company"
author: "Raphael Pereira"
date: "2024-12-07"
output: html_document
---
```{R markdown_setup, include=FALSE}

  # Loading essential packages
    library(dplyr)
    library(writexl)
    library(lubridate)
    library(ggplot2)
    library(leaflet)
 
  # Setting the code language
    Sys.setlocale("LC_TIME", "en_US.UTF-8")
  
  # Configuring my code so results for large numbers won't show in scientific notation
    options(scipen = 999)
  
    bike_rides_raw_df <- read.csv("C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/bike_rides_raw_df.csv")
    bike_rides_main_df <- read.csv("C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/bike_rides_main_df.csv")
    
    count_nulls_dplyr <- function(data){
     data %>% 
      summarize(across(everything(), ~sum(is.na(.))))
    }
  
```

# Introduction
<hr>

This is a capstone study case necessary to conclude the [**Google Data Analytics Professional Certificate**](https://www.coursera.org/professional-certificates/google-data-analytics) course on **Coursera**. Throughout this document, I will perform different analysis on the data provided by the fictional company **Cyclistic**, and respond some business questions. I will adopt as guideline for this project Google's standard data analysis steps:

* **Ask**
* **Prepare**
* **Process**
* **Analyse**
* **Share**
* **Act**

Although this project could be carried using different tools that would fill the same purpose, I opted for using two very versatile softwares for my analysis. I carried this project using excel an Rstudio.
<br>

### Useful information
<hr>
(I NEED TO REFINE THIS SECTION BEFORE FINISHING DOCUMENT)

In order to check my entire code in R studio, you can access  objects: **(IMPLEMENT ON GITHUB)**

* **data_setup.R**
* **data_exploration.R**
* **data_cleaning.R**
* **data_analysis.R**

## Study case and company background


### About Cyclistic

*Cyclistic bike-share* is a fictional bike share company launched in 2016 operating its services throughout Chicago Metropolitan Area in the state of Illinois. According with the initial data provided on the study case, the company has more than **5.800 tracked bicycles**, and has almost **700 stations** scattered across the city. 


Cyclistic clients have a preference for 2 wheel bikes, while only 8% of it's clients use bikes with any assistive options. 30% of the company's bike rides are used for communing purposes, and the majority of it is used for leisure.


The company's marketing states that they were very successful in their past with more flexible pricing-plans, implements options to do single-rides, have unlimited usage with daily passes or have unlimited usage with annual member passes.


It is important to notice that Cyclistic's finance analysts came to the conclusion that annual members were potentially more profitable than casual users, so the company decided to put some work into expanding it's members base by adopting new marketing strategies.


## Data analysis process

## 1. Ask
<hr>

Lily Moreno, the director of marketing, has decided that the company efforts will be towards converting casual users to members, and for that, she needs to understand why would somebody become a member and how could digital media affect future members. The following questions will be helpful and guide me on how to approach this study case:

  1. How do annual members and casual riders use Cyclistic bikes differently?
  2. Why would casual riders buy Cyclistic annual memberships?
  3. How can Cyclistic use digital media to influence casual riders to become members?
  
The question number one will be my main focus on this study, but elements important for the questions two and three will also be developed along the way.

### 1.1 Business task

The company aims to maximize the number of annual memberships to increase profitability. The marketing team will work on studying using habits and understanding how differently members and casual users ride in order to segment targeted marketing strategies to encourage casual users to sign up for the membership.

## 2. Prepare
<hr>

Prepare scripts can be found here: (IMPLEMENT ON GIT HUB)

Data location: [divvy-data](https://divvy-tripdata.s3.amazonaws.com/index.html)<br>
License: [here](https://divvybikes.com/data-license-agreement)
 
#### Data location
All data used during this study and the license for non-profitable use can be found on the links above and complied with the Divvy data license agreement, ensuring no personally identifiable information was accessed or processed.This data was sourced from Divvy's public available trip data, which contains information on bike rides taken in the Chicago Metropolitan Area.

I chose to work with recent data, ranging from **November, 2023** to **October, 2024.**  This data was made available sectioned by months. 

The first step on my journey to analyze this case was to download all the files necessary. There are a total of 12 files, downloaded in a CSV(Comma separated Values) format, using a specific company naming convention that made easier to organize these files.

These data frames had a total of 13 columns each. See the data below to better understand the information I will be working with.:

```{R colnames, echo=FALSE}
  colnames(select(bike_rides_raw_df, -"X"))
```

The raw data is not complete, although every ride has been registered in the period I'm studying, several rows came with wrong or missing information, duplicates and null values. This data frames will give me useful information about using habits over time and where Cyclistic service is more demanded. To start I will describe the process used to clean this data and start working with it effectively. 

## 3. Process
<hr>

Process scripts can be found here: (IMPLEMENT ON GIT HUB)

To work with Cyclistic's data, I had to apply previous knowledge I acquired during the Google Data Analytics Professional Certificate. Excel and RStudio.

Excel was used for initial data exploration due to its ease of use for quick visualization and manipulation of small data sets. RStudio was selected for advanced data cleaning and statistical analysis making it easier to handle large data sets more efficiently.

* [**Excel**](https://www.microsoft.com/en-us/microsoft-365/excel) 
  * I used this tool to initially load my data, and store it in a CSV format that could be manitulated using Rstudio.
* [**R Studio**](https://posit.co/download/rstudio-desktop/) - 
  * This is Integrated Development Environment(IDE) made for the R language. I   where I processed all my data and transformed it into useful insights that will be discussed on this document. I used Rstudio to process all the cleaning in my data.

To clean the data mentioned, I will follow the next steps in order to make my data cleaner and more organized and reliable:

* Uploading and merging data
* Sampling data
* Checking data types
* Checking data for null values
* checking data for duplicates
* Checking for blank values

### 3.1 Data manipulation - Uploading and merging data

  *All the codes for this step can be found [here](________________________________)*
  The first step with my data set was to upload and combine the 12 tables provided into one readable file called bike_rides_112023_102024_df, portraying the subject(Bike rides), the period studied(11/2023 to 10/2024). Note: **df** stands for **data frame** and will be user constantly throughout my code. This step generated a data frame with 5,933,712 rows with individual rides each. 
  
### 3.2 Sampling data

To make working with this data faster, due to hardware limitations, all the calculations from this point and beyond were done using **statistical inference.** For those who are not familiarized with this term, this is how the  [Meriam-Webster](https://www.merriam-webster.com/dictionary/statistical%20inference) Dictionary describes statistical inference:
  
  > *"The making of estimates concerning a population from information gathered from samples"*
  
  Starting with the sample size, I used the sample calculator from [Qualtrics](https://www.qualtrics.com/blog/calculating-sample-size/) to determine what would be considered a safe sample size. Base on this calculator's metric, to achieve a confidence level above 99% in a population of 5933712 with less than 1% margin of error, we could work with any sample larger than 16,531. To be in a comfortable zone, I chose to use a sample size of  593,371, representing 10% of our total population.
  
### 3.3 Data exploration

  All the results for calculations on this section will be done by adjusting it by the population size, which is 10 times larger that our sample.

  Before working with the data to draw conclusions, it is important to make sure the data set we have available is ROCCC(Reliable, Original, Comprehensive, Current and Cited).
  
  * Reliable: This data source is unbiased. It analyzes every ride the company had during a certain period of time. The data doesn't seem to be complete though
  * Original: This data is from the company itself, not relying on third party sources.
  * Comprehensive: Comprehensive data should contain all the data necessary to respond the company's proposed questions. This point will be determined throughout this study.
  * Current: The data we are working with is recent and updated data.
  * Cited: The sources for my data are mentioned in the study case and the data set is easily accessible.

  Now that we know our data is reliable, original, current and cited, let's explore the data.
  
### 3.3.1 Checking data types
  
The data used for this study was organized in 13 columns. The two following images are part of the same table, and will show us the name, data type and some rows for each column.
  
  ![Data frame table part 1](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/glimpse_1.png)
  
Now the second part of our data frame:
  
  ![Data frame table part 2](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/glimpse_2.png)

The columns ride_id, rideable_type, started_at, ended_at, start_station_name, end_station_name, member_casual and day_of_week had a ***character*** type, used to store textual data.
  
  The columns start_lat, start_lng, end_lat, end_lng have a ***dbl*** type, used to describe integer numbers.

### 3.3.2 Checking data for null values
<br>

To make sure the data is complete, we used the function head to look for the presence of null values in any of our columns. The table bellow indicates that we have 748 null rows in our sample for the columns end_lat and end_lng.

  ![Null count](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/count_null.png)
  
When we adjust this data to the population size, the columns **end_lat** and **end_lng** had 7480 rows with null values each, totaling 14960 nulls spotted. One of the things I realized is that many stations have multiple different coordinates, and a theory I will test is that some of the rows with null latitudes and longitudes, probable have other rows with the same station name and with the right coordinates. 

### 3.3.3 Checking data for duplicates

Throughout the data, I also noticed we have some duplicated rows, they will be eliminated in the future to make the data more precise.

There is a total of 5 duplicates for the sample studied or 50 duplicates in the entire population of users.
  
### 3.3.4 Checking for blank values
  
![Blank count.](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/count_blank.png)

  All these columns above had_id had more than 100,000 rolls with blank values each. many rows could have multiple columns with blank spaces.
  
### 3.3.5 Checking for distinct rideable_type

  The data returned 3 types of vehicles that Cyclistic's clients can use. 
  
![Rideable type](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/distinct_count.png)   
  
  After inspecting and exploring the data, I noticed that **748 rows** with null coordinates need to be fixed, 5 duplicates need to be deleted as well and more than 400,000 cells has blank spaces that will be corrected.
  
## 3.4 Data cleaning
  
### 3.4.1 Null values and blank values

  As mentioned before, many stations names in the data frame had very close coordinates. To make sure we have a standard data regarding each station name location, I dropped all the stations with null values.
  
This fixed 748 end_lng and 748 end_lat the null values in the sample.

All the columns with blank values were also removed. After this step,Our data  had 427,250 rows left and 166,008 rows eliminated.
  
### 3.4.2 duplicates

All the five duplicated rows were dropped from the data set, so they don't interfere in out analysis.
  
## 4. Analyze and Share
<hr>

Analyze scripts can be found here: (IMPLEMENT ON GIT HUB)

With the data cleaned and ready to be analyzed, I used R studios to test different hypothesis and draw conclusions about it.

I will check categories like:
* user demographics
* Ride behaviour( e.g., duration, frequency, times)
* Geographical insights(e.g., hotspots, station usage)
* Seasonal trends

This study tries to understand better the using habits of Cyclistic users.

### 4.1  - Measuring Cyclistic's user base post cleaning

Among Cyclistic users, there is a predominance of members(64%), but more than a third of it's clients are casual users(36%), showing a huge market that can be targeted by the marketing team.

```{R user_base_plot, echo=FALSE}
    count_of_users_df <- bike_rides_main_df %>% 
        group_by(
          member_casual
        ) %>% 
        summarize(
          count = n() * 10
        ) %>% 
        arrange(desc(count))

    count_of_users_plot <- ggplot(data = count_of_users_df, aes(x = member_casual, y = count, fill = member_casual)) + 
       geom_bar(stat = "identity", position = position_dodge(width = 0.8)) +
       scale_fill_manual(
         values = c("casual" = "#003f5c", "member" = "#ffa600")
       ) +
       labs(
         title = "Users count - Casual users vs member users",
         x = "User type",
         y = "Count of rides",
         fill = "User type"
       ) +
       theme_minimal()
     
     count_of_users_plot
```
```{R user_base_df, echo=FALSE}
  glimpse(count_of_users_df) 

```

### 4.2  - What type of bikes/scooters user prefer?
  
This data was processed to validate my hypothesis that members would be more inclined to pick electric scooters. The data on the graph above did not support this hypothesis. It shows that 1,68% of the casual members use electric scooters to move around the town. We can also notice that 0,78% of the members use this same service. This tells me that casual users are more inclined to use electric scooters.



```{R user_base_per_rideable_df, echo=FALSE}
    # Table - Count of rides and percentage per rideable_type
      count_of_percentage_per_rideable_df <- bike_rides_main_df %>% 
        group_by(
          member_casual, rideable_type
        ) %>% 
        summarize(
          ride_count = n(),
          .groups = "drop"
        ) %>% 
        group_by(member_casual) %>% 
        mutate(
          percentage = round((ride_count / sum(ride_count)) * 100, 2)
        )

    # Plot - Count of rides per rideable_type
      Count_of_rides_per_rideable_plot  <- ggplot(data = count_of_percentage_per_rideable_df, aes(x = member_casual, y = ride_count, fill = rideable_type)) +
        geom_bar(stat = "identity") +
        scale_fill_manual(
          values = c(
            "classic_bike" = "#665191",
            "electric_bike" = "#d45087",
            "electric_scooter" = "#ff7c43"
          )
        ) +
        labs(
          title = "Vehicle preference per user type",
          x = "Type of user",
          y = "Number of rides"
        ) + 
        theme_minimal()
        
      Count_of_rides_per_rideable_plot
      
    # Table - Count of rides and percentage per rideable_type
      head(count_of_percentage_per_rideable_df)
```

Summary of users:

* Casual users
  * Classic bike - 64%
  * Electric bike - 34.4%
  * Electric Scooter - 1,69%
  
* Members
  * Classic bike - 65,9%
  * Electric bike - 33,3%
  * Electric Scooter - 0,78%

### 4.3  - What is the average usage time of these vehicles?
 
The average trip time of each ride was calculated and grouped that by user type to understand more about the user habits. The plot and table bellow suggests that our casual users tend to take either longer routes or to use the bikes for more time, with an average usage time peaking almost 27 minutes during july, what could be indicative of a more exploratory ride for leisure purposes, while members have a tendency for short rides and very objective paths, with the longest average usage time peak of 13,5 minutes, in June.

```{R avg_usage_time, echo=FALSE}

 #Generating data frame
    avg_ride_duration_df <- bike_rides_main_df %>% 
      mutate(
        month = month(ymd_hms(started_at), label = TRUE, abbr = FALSE)
      ) %>% 
      group_by(
        month, 
        member_casual) %>%
      summarise(
        average_duration = round(mean(usage_time, na.rm = TRUE),2)
      )
    
  # Generating plot
    average_ride_duration_plot <- ggplot(data = avg_ride_duration_df, aes(x = month, y = average_duration, group = member_casual, color = member_casual)) +
      geom_line(
        linewidth = 1.5,
        stat = "identity"
      ) +
      scale_x_discrete(labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")) +
      scale_y_continuous(limits = c(0, 30)) +
      scale_color_manual(values = c("#003f5c", "#ffa600")) +
      labs(
        Title = "Average usage time by user type per month",
        legend = "test"
      ) +
      theme_minimal()
    
    average_ride_duration_plot

```

### 4.4  -   Hotspots for bike rides across the city

The heat map bellow will give us a general perspective of the most used stations in town. This map will have results for all the rides separated by user type(Member or casual). 

Larger circles indicate more activity per station. 

If you're using a web browser to open the original file in html format, this is an interactive map, you can rover your pointer over the circles to see how many rides started on that station. In addition to that, you can zoom in and zoom out the map to better investigate the data.


```{R Heatmap_1, echo=FALSE}
# Generating dataframe for all stations (Both types of user)
    station_usage_df <- bike_rides_main_df %>% 
      group_by(
        start_station_name, 
        member_casual
      ) %>% 
      summarize(
        start_lat = mean(start_lat), # Makes latitud emore uniform. Before the same station had several diff lat
        start_lng = mean(start_lng ), # Makes longitude more uniform. 
        ride_count = n()*10,
        .groups = "drop"
      ) %>% 
      arrange(desc(ride_count)) %>% 
      mutate(
        station_tier = case_when(
          ride_count <= 199 ~ "E",
          ride_count > 199 & ride_count <= 1499 ~ "D",
          ride_count > 1499 & ride_count <= 4999 ~ "C",
          ride_count > 4999 & ride_count <= 12999 ~ "B",
          ride_count > 12999 ~ "A",
          TRUE ~ "N/A" #Default case if no condition it met
        )#Define a tier to the station depending on how many rides it had for members or casual users
      )
    
    # generating leaflet for all stations (Both types of user)
    station_usage_leaflet <- leaflet(data = station_usage_df) %>% 
      addTiles() %>% 
      addCircleMarkers(
        ~start_lng, ~start_lat, #Longitude and latitude
        radius = ~ride_count^(1/4), # Radius on the market scaled by ride_count
        color = ~ifelse(member_casual == "casual", "#003f5c", "#ffa600"), # Color by user type
        fillOpacity = 0.7,
        popup = ~paste0(
          "Station: ", start_station_name, "<br>", 
          "Rides: ", ride_count
        ) 
      ) %>% #Create the popup that will appear then you hover the mouse over the circles
      addLegend(
        "bottomright",
        labels = c("Casual", "Member"),
        title = "User Type",
        colors = c("#003f5c", "#ffa600")
      ) # Creates the legend that will show up on the bottom corner of the map
    
    station_usage_leaflet
```

The next map depicts the same information, but displaying only stations with high concentration of rides starting from(11000 rides or more - Already adjusted by sample size). We can see that casual users have more hot spots along the shoreline, with strong activity near the docs and ports area  of the town.  

This can be due to the abundant presence of tourists that might prefer to use the service as a quick and cheap way to leave the docks and roam across the town. The most used station was the one on Streeter Dr & Grand Avenue, with more than 48,730 rides. This station is located right next to a huge dock for cruise ships and several parks.

```{R leaflet_tier_a_casual, echo=FALSE}
# Generating dataframe for tier "A" stations(per user type)
    station_usage_tier_A_df <- function(user_type){ 
      station_usage_df %>% 
        filter(
          member_casual == user_type,
          station_tier == "A"
        )  
    }
  
  # generating leaflet for Tier "A" stations (One type of user only)
    station_usage_tier_A_leaflet <- function(user_type, color){
      leaflet(data = station_usage_tier_A_df(user_type)) %>% 
        addTiles() %>% 
        addCircleMarkers(
          ~start_lng, ~start_lat, #Longitude and latitude
          radius = ~ride_count^(1/4), # Radius on the market scaled by ride_count
          color = color, # Color by user type
          fillOpacity = 0.9,
          popup = ~paste0(
            "Station: ", start_station_name, "<br>", 
            "Rides: ", ride_count
          ) 
        ) %>% #Create the popup that will appear then you hover the mouse over the circles
        addLegend(
          "bottomright",
          labels = user_type,
          title = "User Type",
          colors = color
        ) # Creates the legend that will show up on the bottom corner of the map
    }
    
    station_usage_tier_A_leaflet("casual", "#003f5c")
```

Next, we can see the activity map for members, with a high concentration of rides near downtown, in areas with large presence of mass transit, which could indicate a possible integration between the bicycles from Ciclystic and mass transit like trains or buses in town. 

Two other location where the rides were very concentrated were near the University of Chicago area, inside the campus, near museums and parks and then near the University of Illinois, one of the largest universities in the state of Illinois. 

The University of Chicago had two stations with high usage:

* University Ave & 57th st with 17200 rides starting there
* Ellis Ave & 55th st with 13700 rides starting there

The university of Illinois had one station with high usage:

* State St & 33rd St with 13740 rides starting there

Other several stations with high usage are located inside and around the Chicago Loop area, a central business district home of large companies like United Airlines, Exelon, CNA Financial, Hyatt and Boeing. This area is also surrounded by an elevated train system, giving the "Loop" name to the area.

```{R leaflet_tier_a_member, echo=FALSE}
  station_usage_tier_A_leaflet("member", "#ffa600")
```

### 4.4  -  When is the client using the bike service?

This section will be split into 3 parts:

  * **Main hours of use**
  * **Week days of use**
  * **Year seasonality**
 
Biking habits can be influenced by a hand full of reasons like leisure, commuting, studying, working, changing health habits, among others. I separated a few more graphs that could help us understanding what influences how out users bike. The hours where this service is used the most could help us understanding more about our user and identifying possible habits that could influence on peak hours.

### 4.4.1 Peak hours for casual users and members

The first graph depicts peak hours for casual users. It show us very few activity on the late night hours, as well as low usage during peak hours between 7a.m. and 8a.m. Casual users tend to use more the bike service by the afternoon, after lunch time. This could be due to a mix of tourists and residents using the bikes for leisure.

```{R peak_hour_1, echo=FALSE}
    # Generating data frame(hourly)
      rides_per_hour_df <- function(user_type){
        bike_rides_main_df %>% 
          filter(member_casual == user_type) %>% 
          mutate(
            hour_of_day = hour(ymd_hms(started_at))
          ) %>% 
          group_by(hour_of_day) %>% 
          summarize(
            ride_count = n(),
            .groups = "drop"
          )
      }
    
    # Generating plot(hourly)
      rides_per_hour_plot <- function(user_type, color_code){
        ggplot(data = rides_per_hour_df(user_type), aes(x = as.numeric(hour_of_day), y = ride_count)) +
        geom_bar(
          stat = "identity",
          fill = color_code
        ) +
        labs(
          title = "Total Trips per day of the week",
          subtitle = "An analysis of rides over time per user type",
          x = "Hour of the day",
          y = "Ride count"
        ) +
        scale_x_continuous(breaks = 0:23) +
        theme_minimal()
      }
      
      rides_per_hour_plot("casual", c("#003f5c"))
      
```

Now notice that when we are doing the same analysis focused on members, the peak hours in the morning also have a drastic increase, indicating a higher activity for the service when people tend to go to work or school/university.

```{R peak_hour_2, echo=FALSE}
    rides_per_hour_plot("member", c("#ffa600"))
```

### 4.4.2 On which days of the week we see more activity for the users?

Considering the average week, the graph shows that the casual users have a very diluted usage of the bikes service on the week days, with a noticeable increase on weekend. This could be indicative of weekend travelers or city residents that don't use the bike service for commuting, but use it for leisure on their days off.

At the same time, members have a heavy usage on the week-days, but that decreases over the weekends. My hypothesis is that this is, motivated by working habits. These are users that use the bikes to commute to work and back.
 
```{R peak_dak_of_week 1, echo=FALSE}
    # Generating data frame(Day of the week)
      rides_per_day_of_week_df <- bike_rides_main_df %>% 
        mutate(
          day_of_week = factor(
            day_of_week,
            levels = c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
          )
        ) %>% 
        group_by(day_of_week, member_casual) %>% 
        summarize(
          ride_count = n(),
          .groups = "drop"
        ) %>% 
        mutate(percentage = round(ride_count / sum(ride_count)*100, 2))

    # Generating plot(Day of the week)
      rides_per_day_of_week_plot <- ggplot(data = rides_per_day_of_week_df, aes(x = day_of_week, y = ride_count, group = member_casual, color = member_casual)) +
        geom_line(linewidth = 1.5) + # Add lines with thickness 1.2
        labs(
          title = "Total Trips per day of the week",
          subtitle = "An analysis of rides over time per user type",
          x = "Day of the week", # Axis title
          y = "Total Trips", # Axis title
          color = "User Type" # Legend title
        ) +
        scale_x_discrete(labels = c("sun", "mon", "tue", "wen", "thu", "fri", "sat")) +
        scale_y_continuous(limits = c(0, NA)) +
        scale_color_manual(values = c("#003f5c", "#ffa600")) +
        theme_minimal()
      
      rides_per_day_of_week_plot
```


### 4.4.3 Annual seasonality on bike usage

I also extracted from the database the annual seasonality for the bike services. This can help us understanding if factors like weather has a role on the number of rides. In order to do that, I will group the data of the last 12 months and inform the frequency of use per month.

```{R seasonality, echo=FALSE}
    # Generating data frame(Month)
      rides_per_month_df <- bike_rides_main_df %>% 
        mutate(
          month = factor(
            format(
              as.POSIXct(started_at, format = "%Y-%m-%d %H:%M:%S"), "%B"
            ), #Extract the months from my data for each ride and
            levels = c(
              "January", "February", "March", "April", "May", "June",
              "July", "August", "September", "October", "November", "December"
            ) #Set in which order my data should be displayed by default
          )
        ) %>% 
        group_by(month, member_casual) %>% 
        summarize(
          ride_count = n(),
          .groups = "drop"
        ) %>% 
        mutate(
          pertentage = round((ride_count/sum(ride_count))*100,2)
        )
    
    # Generating plot(Month)
      rides_per_month_plot <- ggplot(data = rides_per_month_df, aes(x = month, y = ride_count, group = member_casual, color = member_casual)) +
        geom_line(linewidth = 1.2) + # Add lines with thickness 1.2
        labs(
          title = "Total Trips per month in this period",
          subtitle = "An analysis of rides over time per user type",
          x = "Month", # Axis title
          y = "Total Trips", # Axis title
          color = "User Type" # Legend title
        ) +
        scale_x_discrete(labels = c("JAN", "FEB", "MAR", "APR", "MAY", "JUN", "JUL", "AUG", "SEP", "OCT", "NOV", "DEC")) + # Month labels
        scale_color_manual(values = c("#003f5c", "#ffa600")) +
        theme_minimal()  
      
      rides_per_month_plot
```

The graph indicates a higher number of rides between May and October, and low usage during the early and late months of the year. This could be explained due to the drastic changes in temperature throughout the year.

Information about the temperature for the region of Chicago can be found on the National Weather Service website, with data collected by the National Oceanic and Atmospheric Administration [here](https://www.weather.gov/lot/ord_rfd_monthly_yearly_normals). This data show us a similar trend where the warmest months would align with the months with more bike rides.

### 4.4.4 Analysis Summary

#### User base overview
* Cyclistic's user base consists of 2,740,060 members(65%) and 1,532,440 casual users(35%), this numbers shows us a significant opportunity to convert casual users into members.
* Classic bikes are the most popular ride for casual users and members, being used by more than 63% of the users in each group.
* Casual users take longer rides, suggesting leisure and exploration, while members tend to use very short routes, optimal for commuting.
* Casual users prefer stations near the shoreline, parks, docks and tourist areas, while members concentrate their rides near downtown, universities, banks and mass transit hubs.
* Casual users peak usage is in the afternoon, post-lunch, while members have their peak usage on the regular commute hours, between 7-8 AM and at the end of the evening.
* There is a higher usage from May to October, aligning with warmer months, while activity drops during cold months, suggesting seasonal weather influence.

## 5. Act
 <hr>
 
The data acquired with this study case was very useful to me to develop suggestions on how to make this company more competitive, when it comes to number of members. To better understand how to implement any suggestions, first we need to visualize where are the main areas of opportunity for the company.

### 5.1 S.W.O.T analysis

![Cyclists analysis of strengths and weaknesses](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/SWOT.png)

The company offers two very important pricing plans, one that is used by members, where they can ride Cyclist bikes throughout the whole year, and one plan where casual users can take the bike for the day. Although this is a proven business practice, it also exposes the fact that no other plans accommodate the year seasonality. Casual users also do not have enough reasons to subscribe to an annual pass if they usage during Winter is almost 14 times smaller than the usage during Summer.

The company has very strong assets, with a wide net of bike stations and a very large number of bikes, this alone makes the service very accessible in Chicago.

Although the company already leads the bike-share business in that city, the existence of a large number of casual users that are not member is a great opportunity to solidify its position in the market

### 5.2  - How can Cyclistic use digital media to infuence casual riders to become members?

We prepared a series of actions our company and marketing team could take in order to reach a large base of users and increase conversion rates from casual users to members. Please check the table below for a detailed version of these suggestions.

![4W1H](C:/Users/Raphael Pereira/Documents/R projects/R cyclistic project capstone/Main/picture_files/4W1H capstone.png)


The analysis revealed clear distinctions between casual riders and members. Casual riders primarily use bikes for leisure during weekends and afternoons, while members use bikes for commuting during weekdays. These insights highlight the need for targeted marketing strategies that appeal to casual riders' motivations and usage patterns